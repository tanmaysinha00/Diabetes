{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('diabetes_data.csv', \n",
    "                       header = 0, index_col = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   pregnancies  glucose  diastolic  triceps  insulin   bmi    dpf  age  \\\n",
       "0            6      148         72       35        0  33.6  0.627   50   \n",
       "1            1       85         66       29        0  26.6  0.351   31   \n",
       "2            8      183         64        0        0  23.3  0.672   32   \n",
       "3            1       89         66       23       94  28.1  0.167   21   \n",
       "4            0      137         40       35      168  43.1  2.288   33   \n",
       "\n",
       "   diabetes  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pregnancies</th>\n      <th>glucose</th>\n      <th>diastolic</th>\n      <th>triceps</th>\n      <th>insulin</th>\n      <th>bmi</th>\n      <th>dpf</th>\n      <th>age</th>\n      <th>diabetes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(columns = ['diabetes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   pregnancies  glucose  diastolic  triceps  insulin   bmi    dpf  age\n",
       "0            6      148         72       35        0  33.6  0.627   50\n",
       "1            1       85         66       29        0  26.6  0.351   31\n",
       "2            8      183         64        0        0  23.3  0.672   32\n",
       "3            1       89         66       23       94  28.1  0.167   21\n",
       "4            0      137         40       35      168  43.1  2.288   33"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pregnancies</th>\n      <th>glucose</th>\n      <th>diastolic</th>\n      <th>triceps</th>\n      <th>insulin</th>\n      <th>bmi</th>\n      <th>dpf</th>\n      <th>age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df[['diabetes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   diabetes\n",
       "0         1\n",
       "1         0\n",
       "2         1\n",
       "3         0\n",
       "4         1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>diabetes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "n_cols = X_train.shape[1]\n",
    "\n",
    "\n",
    "model.add(Dense(20, input_shape = (n_cols,), activation='relu'))\n",
    "model.add(Dense(10,  activation='relu'))\n",
    "model.add(Dense(10,  activation='relu'))\n",
    "model.add(Dense(1,  activation='sigmoid' ))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_3 (Dense)              (None, 20)                180       \n_________________________________________________________________\ndense_4 (Dense)              (None, 10)                210       \n_________________________________________________________________\ndense_5 (Dense)              (None, 10)                110       \n_________________________________________________________________\ndense_6 (Dense)              (None, 1)                 11        \n=================================================================\nTotal params: 511\nTrainable params: 511\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss: 0.4927 - accuracy: 0.7915\n",
      "Epoch 107/300\n",
      "18/18 [==============================] - 0s 603us/step - loss: 0.4797 - accuracy: 0.7765\n",
      "Epoch 108/300\n",
      "18/18 [==============================] - 0s 558us/step - loss: 0.5021 - accuracy: 0.7725\n",
      "Epoch 109/300\n",
      "18/18 [==============================] - 0s 572us/step - loss: 0.4734 - accuracy: 0.7952\n",
      "Epoch 110/300\n",
      "18/18 [==============================] - 0s 632us/step - loss: 0.5188 - accuracy: 0.7450\n",
      "Epoch 111/300\n",
      "18/18 [==============================] - 0s 523us/step - loss: 0.4709 - accuracy: 0.7917\n",
      "Epoch 112/300\n",
      "18/18 [==============================] - 0s 612us/step - loss: 0.4803 - accuracy: 0.7762\n",
      "Epoch 113/300\n",
      "18/18 [==============================] - 0s 591us/step - loss: 0.4825 - accuracy: 0.7928\n",
      "Epoch 114/300\n",
      "18/18 [==============================] - 0s 500us/step - loss: 0.5081 - accuracy: 0.7836\n",
      "Epoch 115/300\n",
      "18/18 [==============================] - 0s 610us/step - loss: 0.4927 - accuracy: 0.7597\n",
      "Epoch 116/300\n",
      "18/18 [==============================] - 0s 810us/step - loss: 0.4931 - accuracy: 0.7706\n",
      "Epoch 117/300\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4708 - accuracy: 0.7743\n",
      "Epoch 118/300\n",
      "18/18 [==============================] - 0s 617us/step - loss: 0.4938 - accuracy: 0.7780\n",
      "Epoch 119/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7734\n",
      "Epoch 120/300\n",
      "18/18 [==============================] - 0s 603us/step - loss: 0.4679 - accuracy: 0.8143\n",
      "Epoch 121/300\n",
      "18/18 [==============================] - 0s 488us/step - loss: 0.5012 - accuracy: 0.7570\n",
      "Epoch 122/300\n",
      "18/18 [==============================] - 0s 523us/step - loss: 0.4646 - accuracy: 0.7898\n",
      "Epoch 123/300\n",
      "18/18 [==============================] - 0s 460us/step - loss: 0.4754 - accuracy: 0.7718\n",
      "Epoch 124/300\n",
      "18/18 [==============================] - 0s 580us/step - loss: 0.4867 - accuracy: 0.7847\n",
      "Epoch 125/300\n",
      "18/18 [==============================] - 0s 496us/step - loss: 0.4860 - accuracy: 0.7545\n",
      "Epoch 126/300\n",
      "18/18 [==============================] - 0s 494us/step - loss: 0.4708 - accuracy: 0.7933\n",
      "Epoch 127/300\n",
      "18/18 [==============================] - 0s 527us/step - loss: 0.4839 - accuracy: 0.7632\n",
      "Epoch 128/300\n",
      "18/18 [==============================] - 0s 542us/step - loss: 0.5274 - accuracy: 0.7328\n",
      "Epoch 129/300\n",
      "18/18 [==============================] - 0s 508us/step - loss: 0.5311 - accuracy: 0.7330\n",
      "Epoch 130/300\n",
      "18/18 [==============================] - 0s 565us/step - loss: 0.4742 - accuracy: 0.7769\n",
      "Epoch 131/300\n",
      "18/18 [==============================] - 0s 631us/step - loss: 0.5073 - accuracy: 0.7356\n",
      "Epoch 132/300\n",
      "18/18 [==============================] - 0s 471us/step - loss: 0.5213 - accuracy: 0.7470\n",
      "Epoch 133/300\n",
      "18/18 [==============================] - 0s 527us/step - loss: 0.4723 - accuracy: 0.7643\n",
      "Epoch 134/300\n",
      "18/18 [==============================] - 0s 639us/step - loss: 0.4650 - accuracy: 0.7876\n",
      "Epoch 135/300\n",
      "18/18 [==============================] - 0s 481us/step - loss: 0.4825 - accuracy: 0.7857\n",
      "Epoch 136/300\n",
      "18/18 [==============================] - 0s 540us/step - loss: 0.4490 - accuracy: 0.8049\n",
      "Epoch 137/300\n",
      "18/18 [==============================] - 0s 447us/step - loss: 0.4945 - accuracy: 0.7492\n",
      "Epoch 138/300\n",
      "18/18 [==============================] - 0s 556us/step - loss: 0.4889 - accuracy: 0.7744\n",
      "Epoch 139/300\n",
      "18/18 [==============================] - 0s 663us/step - loss: 0.4735 - accuracy: 0.7758\n",
      "Epoch 140/300\n",
      "18/18 [==============================] - 0s 461us/step - loss: 0.4688 - accuracy: 0.7858\n",
      "Epoch 141/300\n",
      "18/18 [==============================] - 0s 570us/step - loss: 0.4884 - accuracy: 0.7793\n",
      "Epoch 142/300\n",
      "18/18 [==============================] - 0s 624us/step - loss: 0.4703 - accuracy: 0.7858\n",
      "Epoch 143/300\n",
      "18/18 [==============================] - 0s 639us/step - loss: 0.4840 - accuracy: 0.7870\n",
      "Epoch 144/300\n",
      "18/18 [==============================] - 0s 620us/step - loss: 0.4579 - accuracy: 0.7989\n",
      "Epoch 145/300\n",
      "18/18 [==============================] - 0s 606us/step - loss: 0.4973 - accuracy: 0.7527\n",
      "Epoch 146/300\n",
      "18/18 [==============================] - 0s 539us/step - loss: 0.4941 - accuracy: 0.7761\n",
      "Epoch 147/300\n",
      "18/18 [==============================] - 0s 636us/step - loss: 0.4598 - accuracy: 0.8052\n",
      "Epoch 148/300\n",
      "18/18 [==============================] - 0s 551us/step - loss: 0.4747 - accuracy: 0.7735\n",
      "Epoch 149/300\n",
      "18/18 [==============================] - 0s 562us/step - loss: 0.4907 - accuracy: 0.7745\n",
      "Epoch 150/300\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7965\n",
      "Epoch 151/300\n",
      "18/18 [==============================] - 0s 521us/step - loss: 0.4578 - accuracy: 0.7919\n",
      "Epoch 152/300\n",
      "18/18 [==============================] - 0s 555us/step - loss: 0.4664 - accuracy: 0.7947\n",
      "Epoch 153/300\n",
      "18/18 [==============================] - 0s 684us/step - loss: 0.4803 - accuracy: 0.7803\n",
      "Epoch 154/300\n",
      "18/18 [==============================] - 0s 560us/step - loss: 0.4438 - accuracy: 0.8040\n",
      "Epoch 155/300\n",
      "18/18 [==============================] - 0s 552us/step - loss: 0.4798 - accuracy: 0.7851\n",
      "Epoch 156/300\n",
      "18/18 [==============================] - 0s 566us/step - loss: 0.4715 - accuracy: 0.8003\n",
      "Epoch 157/300\n",
      "18/18 [==============================] - 0s 511us/step - loss: 0.4838 - accuracy: 0.7835\n",
      "Epoch 158/300\n",
      "18/18 [==============================] - 0s 630us/step - loss: 0.4757 - accuracy: 0.7846\n",
      "Epoch 159/300\n",
      "18/18 [==============================] - 0s 537us/step - loss: 0.4669 - accuracy: 0.8136\n",
      "Epoch 160/300\n",
      "18/18 [==============================] - 0s 724us/step - loss: 0.4852 - accuracy: 0.7720\n",
      "Epoch 161/300\n",
      "18/18 [==============================] - 0s 657us/step - loss: 0.4857 - accuracy: 0.7674\n",
      "Epoch 162/300\n",
      "18/18 [==============================] - 0s 675us/step - loss: 0.4910 - accuracy: 0.7658\n",
      "Epoch 163/300\n",
      "18/18 [==============================] - 0s 591us/step - loss: 0.4594 - accuracy: 0.7929\n",
      "Epoch 164/300\n",
      "18/18 [==============================] - 0s 650us/step - loss: 0.4476 - accuracy: 0.8062\n",
      "Epoch 165/300\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.7778\n",
      "Epoch 166/300\n",
      "18/18 [==============================] - 0s 552us/step - loss: 0.4922 - accuracy: 0.8050\n",
      "Epoch 167/300\n",
      "18/18 [==============================] - 0s 537us/step - loss: 0.4723 - accuracy: 0.7933\n",
      "Epoch 168/300\n",
      "18/18 [==============================] - 0s 721us/step - loss: 0.5024 - accuracy: 0.7708\n",
      "Epoch 169/300\n",
      "18/18 [==============================] - 0s 607us/step - loss: 0.4713 - accuracy: 0.7838\n",
      "Epoch 170/300\n",
      "18/18 [==============================] - 0s 463us/step - loss: 0.4260 - accuracy: 0.8289\n",
      "Epoch 171/300\n",
      "18/18 [==============================] - 0s 511us/step - loss: 0.4732 - accuracy: 0.7938\n",
      "Epoch 172/300\n",
      "18/18 [==============================] - 0s 429us/step - loss: 0.4641 - accuracy: 0.7881\n",
      "Epoch 173/300\n",
      "18/18 [==============================] - 0s 495us/step - loss: 0.4647 - accuracy: 0.8012\n",
      "Epoch 174/300\n",
      "18/18 [==============================] - 0s 613us/step - loss: 0.4595 - accuracy: 0.7984\n",
      "Epoch 175/300\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7746\n",
      "Epoch 176/300\n",
      "18/18 [==============================] - 0s 859us/step - loss: 0.4898 - accuracy: 0.7592\n",
      "Epoch 177/300\n",
      "18/18 [==============================] - 0s 766us/step - loss: 0.4964 - accuracy: 0.7468\n",
      "Epoch 178/300\n",
      "18/18 [==============================] - 0s 595us/step - loss: 0.4908 - accuracy: 0.7590\n",
      "Epoch 179/300\n",
      "18/18 [==============================] - 0s 439us/step - loss: 0.4767 - accuracy: 0.7970\n",
      "Epoch 180/300\n",
      "18/18 [==============================] - 0s 460us/step - loss: 0.5025 - accuracy: 0.7667\n",
      "Epoch 181/300\n",
      "18/18 [==============================] - 0s 435us/step - loss: 0.4336 - accuracy: 0.8087\n",
      "Epoch 182/300\n",
      "18/18 [==============================] - 0s 450us/step - loss: 0.4780 - accuracy: 0.7596\n",
      "Epoch 183/300\n",
      "18/18 [==============================] - 0s 484us/step - loss: 0.4612 - accuracy: 0.8018\n",
      "Epoch 184/300\n",
      "18/18 [==============================] - 0s 428us/step - loss: 0.4657 - accuracy: 0.7985\n",
      "Epoch 185/300\n",
      "18/18 [==============================] - 0s 491us/step - loss: 0.4735 - accuracy: 0.7848\n",
      "Epoch 186/300\n",
      "18/18 [==============================] - 0s 410us/step - loss: 0.4636 - accuracy: 0.7804\n",
      "Epoch 187/300\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7922\n",
      "Epoch 188/300\n",
      "18/18 [==============================] - 0s 624us/step - loss: 0.4544 - accuracy: 0.7993\n",
      "Epoch 189/300\n",
      "18/18 [==============================] - 0s 482us/step - loss: 0.4444 - accuracy: 0.8025\n",
      "Epoch 190/300\n",
      "18/18 [==============================] - 0s 482us/step - loss: 0.4707 - accuracy: 0.7728\n",
      "Epoch 191/300\n",
      "18/18 [==============================] - 0s 449us/step - loss: 0.4539 - accuracy: 0.7987\n",
      "Epoch 192/300\n",
      "18/18 [==============================] - 0s 451us/step - loss: 0.4875 - accuracy: 0.7714\n",
      "Epoch 193/300\n",
      "18/18 [==============================] - 0s 406us/step - loss: 0.4607 - accuracy: 0.7785\n",
      "Epoch 194/300\n",
      "18/18 [==============================] - 0s 447us/step - loss: 0.4654 - accuracy: 0.7983\n",
      "Epoch 195/300\n",
      "18/18 [==============================] - 0s 543us/step - loss: 0.4955 - accuracy: 0.7748\n",
      "Epoch 196/300\n",
      "18/18 [==============================] - 0s 464us/step - loss: 0.4740 - accuracy: 0.7711\n",
      "Epoch 197/300\n",
      "18/18 [==============================] - 0s 397us/step - loss: 0.4796 - accuracy: 0.7835\n",
      "Epoch 198/300\n",
      "18/18 [==============================] - 0s 505us/step - loss: 0.4476 - accuracy: 0.7960\n",
      "Epoch 199/300\n",
      "18/18 [==============================] - 0s 788us/step - loss: 0.4773 - accuracy: 0.7743\n",
      "Epoch 200/300\n",
      "18/18 [==============================] - 0s 417us/step - loss: 0.4462 - accuracy: 0.7910\n",
      "Epoch 201/300\n",
      "18/18 [==============================] - 0s 513us/step - loss: 0.4804 - accuracy: 0.7622\n",
      "Epoch 202/300\n",
      "18/18 [==============================] - 0s 424us/step - loss: 0.4545 - accuracy: 0.7968\n",
      "Epoch 203/300\n",
      "18/18 [==============================] - 0s 410us/step - loss: 0.4641 - accuracy: 0.7937\n",
      "Epoch 204/300\n",
      "18/18 [==============================] - 0s 408us/step - loss: 0.4597 - accuracy: 0.8010\n",
      "Epoch 205/300\n",
      "18/18 [==============================] - 0s 455us/step - loss: 0.4526 - accuracy: 0.7897\n",
      "Epoch 206/300\n",
      "18/18 [==============================] - 0s 457us/step - loss: 0.4898 - accuracy: 0.7392\n",
      "Epoch 207/300\n",
      "18/18 [==============================] - 0s 444us/step - loss: 0.4444 - accuracy: 0.7907\n",
      "Epoch 208/300\n",
      "18/18 [==============================] - 0s 470us/step - loss: 0.4632 - accuracy: 0.7930\n",
      "Epoch 209/300\n",
      "18/18 [==============================] - 0s 365us/step - loss: 0.4538 - accuracy: 0.7902\n",
      "Epoch 210/300\n",
      "18/18 [==============================] - 0s 503us/step - loss: 0.4771 - accuracy: 0.7695\n",
      "Epoch 211/300\n",
      "18/18 [==============================] - 0s 366us/step - loss: 0.4675 - accuracy: 0.7953\n",
      "Epoch 212/300\n",
      "18/18 [==============================] - 0s 498us/step - loss: 0.4556 - accuracy: 0.7873\n",
      "Epoch 213/300\n",
      "18/18 [==============================] - 0s 399us/step - loss: 0.4556 - accuracy: 0.8176\n",
      "Epoch 214/300\n",
      "18/18 [==============================] - 0s 524us/step - loss: 0.4680 - accuracy: 0.7777\n",
      "Epoch 215/300\n",
      "18/18 [==============================] - 0s 403us/step - loss: 0.4490 - accuracy: 0.7958\n",
      "Epoch 216/300\n",
      "18/18 [==============================] - 0s 513us/step - loss: 0.4731 - accuracy: 0.7852\n",
      "Epoch 217/300\n",
      "18/18 [==============================] - 0s 439us/step - loss: 0.4554 - accuracy: 0.8021\n",
      "Epoch 218/300\n",
      "18/18 [==============================] - 0s 430us/step - loss: 0.4298 - accuracy: 0.8047\n",
      "Epoch 219/300\n",
      "18/18 [==============================] - 0s 430us/step - loss: 0.4476 - accuracy: 0.8008\n",
      "Epoch 220/300\n",
      "18/18 [==============================] - 0s 375us/step - loss: 0.4353 - accuracy: 0.8093\n",
      "Epoch 221/300\n",
      "18/18 [==============================] - 0s 444us/step - loss: 0.4340 - accuracy: 0.7931\n",
      "Epoch 222/300\n",
      "18/18 [==============================] - 0s 967us/step - loss: 0.4569 - accuracy: 0.7734\n",
      "Epoch 223/300\n",
      "18/18 [==============================] - 0s 525us/step - loss: 0.4460 - accuracy: 0.7889\n",
      "Epoch 224/300\n",
      "18/18 [==============================] - 0s 388us/step - loss: 0.4602 - accuracy: 0.7887\n",
      "Epoch 225/300\n",
      "18/18 [==============================] - 0s 377us/step - loss: 0.4736 - accuracy: 0.7658\n",
      "Epoch 226/300\n",
      "18/18 [==============================] - 0s 551us/step - loss: 0.4561 - accuracy: 0.7891\n",
      "Epoch 227/300\n",
      "18/18 [==============================] - 0s 396us/step - loss: 0.4452 - accuracy: 0.8114\n",
      "Epoch 228/300\n",
      "18/18 [==============================] - 0s 452us/step - loss: 0.4651 - accuracy: 0.7871\n",
      "Epoch 229/300\n",
      "18/18 [==============================] - 0s 414us/step - loss: 0.4243 - accuracy: 0.8088\n",
      "Epoch 230/300\n",
      "18/18 [==============================] - 0s 399us/step - loss: 0.4389 - accuracy: 0.8074\n",
      "Epoch 231/300\n",
      "18/18 [==============================] - 0s 427us/step - loss: 0.4507 - accuracy: 0.7912\n",
      "Epoch 232/300\n",
      "18/18 [==============================] - 0s 479us/step - loss: 0.4754 - accuracy: 0.7792\n",
      "Epoch 233/300\n",
      "18/18 [==============================] - 0s 468us/step - loss: 0.4230 - accuracy: 0.8104\n",
      "Epoch 234/300\n",
      "18/18 [==============================] - 0s 428us/step - loss: 0.4154 - accuracy: 0.8283\n",
      "Epoch 235/300\n",
      "18/18 [==============================] - 0s 453us/step - loss: 0.4751 - accuracy: 0.7901\n",
      "Epoch 236/300\n",
      "18/18 [==============================] - 0s 437us/step - loss: 0.4129 - accuracy: 0.8042\n",
      "Epoch 237/300\n",
      "18/18 [==============================] - 0s 465us/step - loss: 0.4459 - accuracy: 0.7998\n",
      "Epoch 238/300\n",
      "18/18 [==============================] - 0s 408us/step - loss: 0.4837 - accuracy: 0.7873\n",
      "Epoch 239/300\n",
      "18/18 [==============================] - 0s 487us/step - loss: 0.4819 - accuracy: 0.7814\n",
      "Epoch 240/300\n",
      "18/18 [==============================] - 0s 488us/step - loss: 0.4750 - accuracy: 0.7681\n",
      "Epoch 241/300\n",
      "18/18 [==============================] - 0s 502us/step - loss: 0.4416 - accuracy: 0.7866\n",
      "Epoch 242/300\n",
      "18/18 [==============================] - 0s 424us/step - loss: 0.4309 - accuracy: 0.8204\n",
      "Epoch 243/300\n",
      "18/18 [==============================] - 0s 494us/step - loss: 0.4456 - accuracy: 0.8064\n",
      "Epoch 244/300\n",
      "18/18 [==============================] - 0s 429us/step - loss: 0.4353 - accuracy: 0.8044\n",
      "Epoch 245/300\n",
      "18/18 [==============================] - 0s 434us/step - loss: 0.4157 - accuracy: 0.8194\n",
      "Epoch 246/300\n",
      "18/18 [==============================] - 0s 468us/step - loss: 0.4207 - accuracy: 0.8148\n",
      "Epoch 247/300\n",
      "18/18 [==============================] - 0s 390us/step - loss: 0.4477 - accuracy: 0.7925\n",
      "Epoch 248/300\n",
      "18/18 [==============================] - 0s 476us/step - loss: 0.4571 - accuracy: 0.7840\n",
      "Epoch 249/300\n",
      "18/18 [==============================] - 0s 432us/step - loss: 0.4236 - accuracy: 0.7908\n",
      "Epoch 250/300\n",
      "18/18 [==============================] - 0s 482us/step - loss: 0.4699 - accuracy: 0.7761\n",
      "Epoch 251/300\n",
      "18/18 [==============================] - 0s 408us/step - loss: 0.4499 - accuracy: 0.7914\n",
      "Epoch 252/300\n",
      "18/18 [==============================] - 0s 455us/step - loss: 0.4499 - accuracy: 0.7737\n",
      "Epoch 253/300\n",
      "18/18 [==============================] - 0s 378us/step - loss: 0.4467 - accuracy: 0.8112\n",
      "Epoch 254/300\n",
      "18/18 [==============================] - 0s 491us/step - loss: 0.4567 - accuracy: 0.7837\n",
      "Epoch 255/300\n",
      "18/18 [==============================] - 0s 378us/step - loss: 0.4183 - accuracy: 0.8312\n",
      "Epoch 256/300\n",
      "18/18 [==============================] - 0s 551us/step - loss: 0.4602 - accuracy: 0.7853\n",
      "Epoch 257/300\n",
      "18/18 [==============================] - 0s 437us/step - loss: 0.4204 - accuracy: 0.8089\n",
      "Epoch 258/300\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4156 - accuracy: 0.8088\n",
      "Epoch 259/300\n",
      "18/18 [==============================] - 0s 646us/step - loss: 0.4489 - accuracy: 0.8021\n",
      "Epoch 260/300\n",
      "18/18 [==============================] - 0s 513us/step - loss: 0.4371 - accuracy: 0.8173\n",
      "Epoch 261/300\n",
      "18/18 [==============================] - 0s 472us/step - loss: 0.4316 - accuracy: 0.7999\n",
      "Epoch 262/300\n",
      "18/18 [==============================] - 0s 457us/step - loss: 0.4488 - accuracy: 0.7800\n",
      "Epoch 263/300\n",
      "18/18 [==============================] - 0s 414us/step - loss: 0.4457 - accuracy: 0.8010\n",
      "Epoch 264/300\n",
      "18/18 [==============================] - 0s 458us/step - loss: 0.4254 - accuracy: 0.8064\n",
      "Epoch 265/300\n",
      "18/18 [==============================] - 0s 497us/step - loss: 0.4202 - accuracy: 0.8076\n",
      "Epoch 266/300\n",
      "18/18 [==============================] - 0s 420us/step - loss: 0.4473 - accuracy: 0.7854\n",
      "Epoch 267/300\n",
      "18/18 [==============================] - 0s 465us/step - loss: 0.4187 - accuracy: 0.8244\n",
      "Epoch 268/300\n",
      "18/18 [==============================] - 0s 424us/step - loss: 0.4374 - accuracy: 0.8099\n",
      "Epoch 269/300\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4150 - accuracy: 0.8131\n",
      "Epoch 270/300\n",
      "18/18 [==============================] - 0s 506us/step - loss: 0.4714 - accuracy: 0.7807\n",
      "Epoch 271/300\n",
      "18/18 [==============================] - 0s 557us/step - loss: 0.4143 - accuracy: 0.7974\n",
      "Epoch 272/300\n",
      "18/18 [==============================] - 0s 449us/step - loss: 0.4285 - accuracy: 0.8099\n",
      "Epoch 273/300\n",
      "18/18 [==============================] - 0s 419us/step - loss: 0.4173 - accuracy: 0.8226\n",
      "Epoch 274/300\n",
      "18/18 [==============================] - 0s 514us/step - loss: 0.4495 - accuracy: 0.8034\n",
      "Epoch 275/300\n",
      "18/18 [==============================] - 0s 429us/step - loss: 0.4219 - accuracy: 0.8180\n",
      "Epoch 276/300\n",
      "18/18 [==============================] - 0s 444us/step - loss: 0.4190 - accuracy: 0.8236\n",
      "Epoch 277/300\n",
      "18/18 [==============================] - 0s 420us/step - loss: 0.4124 - accuracy: 0.8129\n",
      "Epoch 278/300\n",
      "18/18 [==============================] - 0s 528us/step - loss: 0.4307 - accuracy: 0.8176\n",
      "Epoch 279/300\n",
      "18/18 [==============================] - 0s 455us/step - loss: 0.4336 - accuracy: 0.8093\n",
      "Epoch 280/300\n",
      "18/18 [==============================] - 0s 431us/step - loss: 0.4262 - accuracy: 0.8219\n",
      "Epoch 281/300\n",
      "18/18 [==============================] - 0s 466us/step - loss: 0.4106 - accuracy: 0.8359\n",
      "Epoch 282/300\n",
      "18/18 [==============================] - 0s 454us/step - loss: 0.4190 - accuracy: 0.8230\n",
      "Epoch 283/300\n",
      "18/18 [==============================] - 0s 482us/step - loss: 0.4387 - accuracy: 0.7916\n",
      "Epoch 284/300\n",
      "18/18 [==============================] - 0s 438us/step - loss: 0.4055 - accuracy: 0.8430\n",
      "Epoch 285/300\n",
      "18/18 [==============================] - 0s 528us/step - loss: 0.4349 - accuracy: 0.7948\n",
      "Epoch 286/300\n",
      "18/18 [==============================] - 0s 496us/step - loss: 0.4751 - accuracy: 0.7909\n",
      "Epoch 287/300\n",
      "18/18 [==============================] - 0s 496us/step - loss: 0.4967 - accuracy: 0.7532\n",
      "Epoch 288/300\n",
      "18/18 [==============================] - 0s 467us/step - loss: 0.4474 - accuracy: 0.7898\n",
      "Epoch 289/300\n",
      "18/18 [==============================] - 0s 421us/step - loss: 0.4581 - accuracy: 0.7674\n",
      "Epoch 290/300\n",
      "18/18 [==============================] - 0s 473us/step - loss: 0.4356 - accuracy: 0.7971\n",
      "Epoch 291/300\n",
      "18/18 [==============================] - 0s 429us/step - loss: 0.4207 - accuracy: 0.8054\n",
      "Epoch 292/300\n",
      "18/18 [==============================] - 0s 528us/step - loss: 0.4155 - accuracy: 0.7985\n",
      "Epoch 293/300\n",
      "18/18 [==============================] - 0s 454us/step - loss: 0.3947 - accuracy: 0.8203\n",
      "Epoch 294/300\n",
      "18/18 [==============================] - 0s 508us/step - loss: 0.4260 - accuracy: 0.7910\n",
      "Epoch 295/300\n",
      "18/18 [==============================] - 0s 439us/step - loss: 0.4222 - accuracy: 0.8188\n",
      "Epoch 296/300\n",
      "18/18 [==============================] - 0s 708us/step - loss: 0.4198 - accuracy: 0.8110\n",
      "Epoch 297/300\n",
      "18/18 [==============================] - 0s 453us/step - loss: 0.4531 - accuracy: 0.7909\n",
      "Epoch 298/300\n",
      "18/18 [==============================] - 0s 450us/step - loss: 0.4010 - accuracy: 0.8193\n",
      "Epoch 299/300\n",
      "18/18 [==============================] - 0s 409us/step - loss: 0.4131 - accuracy: 0.8132\n",
      "Epoch 300/300\n",
      "18/18 [==============================] - 0s 427us/step - loss: 0.4186 - accuracy: 0.8077\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy: 75.52%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3810jvsc74a57bd0fdeb9ba6c8a55bd50559d038157aa049c92529bc5c6bc0f15bd834c8abd7b59b",
   "display_name": "Python 3.8.10 64-bit ('tf': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "fdeb9ba6c8a55bd50559d038157aa049c92529bc5c6bc0f15bd834c8abd7b59b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}